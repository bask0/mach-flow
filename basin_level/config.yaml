# pytorch_lightning==2.1.0
seed_everything: 99
trainer:
  num_nodes: 1
  callbacks:
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: 'val_loss'
        patience: 20
        min_delta: 0.0
        mode: 'min'
    - class_path: lightning.pytorch.callbacks.TQDMProgressBar
      init_args:
        refresh_rate: 1
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: 'val_loss'
        mode: min
        filename: 'best'
        save_last: true
        save_top_k: 1
  gradient_clip_val: 1.0
  fast_dev_run: false
  max_steps: -1
  max_epochs: -1
  overfit_batches: 0.0
  check_val_every_n_epoch: 1
  accumulate_grad_batches: 1
data:
  class_path: dataset.machflowdata.MachFlowDataModule
  init_args:
    machflow_data_path:
    - "/data/basil/harmonized_basins.zarr/"
    - "/mydata/machflow/basil/data/harmonized_basins.zarr/"
    features:
    - P
    - T
    targets:
    - Qmm
    stat_features:
    - 'area'
    train_window_size: 730
    window_min_count: 30
    train_num_samples_per_epoch: 30
    warmup_size: 365
    drop_all_nan_stations: true
    num_cv_folds: 8
    fold_nr: 0
    use_additional_basins_as_training: false
    train_tranges:
    - "1961,1991"
    - "2002,2013"
    valid_tranges:
    - "1992,1993"
    - "2000,2001"
    - "2014,2015"
    - "2021,2023"
    test_tranges:
    - "1994,1999"
    - "2016,2020"
    predict_tslice:
    - "1961"
    - "2023"
    norm_features: true
    norm_stat_features: true
    norm_targets: true
    batch_size: 32
    num_workers: 4
    seed: 19
optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 0.01
    weight_decay: 0.01
criterion:
  name: l2
  sqrt_transform: false
